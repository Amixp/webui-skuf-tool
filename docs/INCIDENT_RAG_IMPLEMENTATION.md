# Реализация RAG-агента для инцидент-менеджмента

## Обзор

Реализация подхода из статьи [RAG-агент для автоматизации инцидент-менеджмента](INCIDENT_RAG_APPROACH.md) с использованием:
- Переформулировки запросов через LLM
- Двойного поиска (по оригиналу и переформулированному описанию)
- Генерации рекомендаций на основе найденных похожих случаев

## Установка и настройка

### 1. Создание таблицы incidents

Таблица создается автоматически при инициализации БД через `init_incidents.sql`.

Для ручного создания:

```bash
# В контейнере postgres
psql -U rag_user -d rag_db -f /app/init_incidents.sql
```

Или через docker:

```bash
docker exec -i rag-postgres psql -U rag_user -d rag_db < init_incidents.sql
```

### 2. Импорт данных из CSV

Импорт инцидентов из CSV файлов:

```bash
python3 scripts/import_incidents_from_csv.py skuf/INC.csv --mode append
```

**Параметры:**
- `--mode append` - добавить новые инциденты (по умолчанию)
- `--mode replace` - заменить все существующие инциденты

**Что импортируется:**
- Номер инцидента
- Даты создания и решения
- Описание и решение
- Метаданные (приоритет, статус, услуга и т.д.)

### 3. Векторизация инцидентов

Создание эмбеддингов для оригинальных и переформулированных описаний:

```bash
python3 scripts/vectorize_incidents.py
```

**Переменные окружения:**
- `BATCH_SIZE` - размер батча (по умолчанию 64)
- `LIMIT` - лимит инцидентов для обработки (0 = без ограничений)
- `EMBEDDING_MODEL` - модель эмбеддинга (по умолчанию bge-m3)
- `OLLAMA_BASE_URL` - URL Ollama сервера

**Важно:** 
- Размерность эмбеддингов должна быть 1024 (для ru-en-RoSBERTa)
- Если используется другая модель, нужно изменить размерность в БД

### 4. Переформулировка описаний (опционально)

Перед векторизацией можно переформулировать описания через LLM:

```python
from incident_rag_service import IncidentRAGService
from chat_app import DatabaseManager, OllamaClient

db = DatabaseManager()
ollama = OllamaClient()
service = IncidentRAGService(db, ollama)

# Переформулировка описания
reformulated = await service.reformulate_description("Приложение не работает")
```

Затем обновить поле `description_reformulated` в таблице incidents.

## Использование API

### Эндпоинт поиска похожих инцидентов

```bash
curl -X POST http://localhost:8000/incidents/search \
  -H "Content-Type: application/json" \
  -d '{
    "description": "Приложение не запускается, ошибка подключения к базе данных",
    "use_reformulation": true
  }'
```

**Ответ:**
```json
{
  "description": "Приложение не запускается, ошибка подключения к базе данных",
  "similar_incidents": [
    {
      "id": 1,
      "number": "INC000001234",
      "creation_date": "2024-01-15",
      "description": "...",
      "solution": "...",
      "service": "База данных",
      "score": 0.85,
      "distance": 0.15,
      "search_type": "original"
    }
  ],
  "recommendation": "На основе анализа похожих инцидентов...",
  "similar_incidents_count": 5,
  "timestamp": "2024-01-20 10:30:00"
}
```

### Параметры запроса

| Параметр | Тип | Обязательный | По умолчанию | Описание |
|----------|-----|--------------|--------------|----------|
| `description` | string | Да | - | Описание инцидента для поиска |
| `use_reformulation` | boolean | Нет | true | Использовать ли переформулировку через LLM |

## Конфигурация

### Переменные окружения

Добавьте в `.env`:

```bash
# Модель LLM для переформулировки и генерации рекомендаций
INCIDENT_LLM_MODEL=qwen3:8b

# Порог релевантности (как в статье: 0.15)
INCIDENT_SIMILARITY_THRESHOLD=0.15

# Лимит похожих инцидентов для контекста
INCIDENT_CONTEXT_LIMIT=10
```

### Настройка порога релевантности

Порог `INCIDENT_SIMILARITY_THRESHOLD` определяет минимальную релевантность для включения инцидента в результаты.

**Рекомендации:**
- `0.15` - строгий порог (как в статье), только очень похожие инциденты
- `0.3-0.4` - средний порог, баланс между точностью и охватом
- `0.0` - без фильтрации, все найденные инциденты

## Архитектура

### Компоненты

1. **IncidentRAGService** (`incident_rag_service.py`)
   - Переформулировка описаний через LLM
   - Получение эмбеддингов
   - Поиск похожих инцидентов (двойной поиск)
   - Генерация рекомендаций

2. **SQL функции** (`init_incidents.sql`)
   - `search_similar_incidents_by_description()` - поиск по оригиналу
   - `search_similar_incidents_by_reformulated()` - поиск по переформулированному
   - `search_similar_incidents_combined()` - объединенный поиск

3. **API эндпоинт** (`chat_app.py`)
   - `/incidents/search` - поиск и генерация рекомендаций

### Процесс обработки

1. **Получение описания инцидента**
2. **Переформулировка** (опционально) через LLM
3. **Векторизация** обоих описаний
4. **Двойной поиск** в БД:
   - По оригинальному описанию (топ-5)
   - По переформулированному описанию (топ-5)
   - Дедупликация результатов
5. **Генерация рекомендации** на основе найденных похожих случаев

## Отличия от подхода в статье

### Что реализовано

✅ Переформулировка запросов через LLM  
✅ Двойной поиск (по оригиналу и переформулированному)  
✅ Настройка порога релевантности (0.15)  
✅ Генерация рекомендаций на основе похожих случаев  
✅ SQL функции для эффективного поиска  

### Что отличается

⚠️ **Модель эмбеддинга:** В статье используется ru-en-RoSBERTa (1024), в проекте по умолчанию bge-m3 (768).  
   - Для полного соответствия нужно использовать ru-en-RoSBERTa или изменить размерность в БД

⚠️ **LangChain:** В статье используется LangChain, в проекте реализовано напрямую через Ollama API  
   - Можно добавить LangChain для более сложных цепочек

⚠️ **Интеграция с Service Desk:** В статье есть интеграция с системой Service Desk, в проекте только API  
   - Можно добавить интеграцию через webhook или периодический опрос

## Производительность

### Ожидаемые метрики (из статьи)

- **Время обработки:** 1-2 минуты на инцидент
- **Экономия времени:** ~10 минут на инцидент
- **Точность:** Высокая при наличии похожих случаев в БД

### Оптимизация

1. **Индексы:** Векторные индексы ivfflat для быстрого поиска
2. **Батчинг:** Обработка эмбеддингов батчами
3. **Кэширование:** Можно добавить кэширование переформулировок

## Следующие шаги

1. **Тестирование** на реальных данных
2. **Настройка порога** релевантности под конкретные данные
3. **Интеграция ru-en-RoSBERTa** для полного соответствия статье
4. **Добавление LangChain** для более сложных цепочек
5. **Мониторинг** качества рекомендаций

## Troubleshooting

### Проблема: Низкая релевантность результатов

**Решение:**
- Проверьте качество эмбеддингов
- Убедитесь, что размерность соответствует модели
- Попробуйте снизить порог релевантности

### Проблема: Медленная обработка

**Решение:**
- Уменьшите `INCIDENT_CONTEXT_LIMIT`
- Используйте более быструю модель LLM
- Оптимизируйте индексы в БД

### Проблема: Ошибки векторизации

**Решение:**
- Проверьте, что Ollama запущен и модель загружена
- Убедитесь, что размерность эмбеддингов соответствует БД (1024)
- Проверьте логи `vectorize_incidents.log`
